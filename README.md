## 1. Resumen del proyecto

Este repositorio contiene la pr√°ctica que integra cuatro m√≥dulos principales para una aplicaci√≥n de movilidad urbana:

- **YOLO** para detecci√≥n de ‚â•3 categor√≠as relevantes (ej.: `car`, `bicycle`, `person`, `motorcycle`).
- **SAM (Segment Anything)** para generar m√°scaras √∫tiles (recortes, c√°lculo de √°rea en p√≠xeles).
- **MiDaS** para estimar profundidad monocular y clasificar cada detecci√≥n en tres bins: **cerca / medio / lejos** (comparado con la mediana de la escena).
- **MediaPipe (Hands)** para control manos-free: gestos como `siguiente escena` o `captura` (trigger).

---

## 2. Referencias

- YOLOv8 (Ultralytics): https://github.com/ultralytics/ultralytics
- Segment Anything (SAM): https://github.com/facebookresearch/segment-anything
- MiDaS (Depth Estimation): https://github.com/isl-org/MiDaS
- MediaPipe Hands: https://developers.google.com/mediapipe/solutions/vision/hand_landmarker

---

## 4. Pipeline (diagrama + explicaci√≥n breve)

```mermaid
graph TD
    A[üì∑ Entrada: Imagen/Video] --> B[üîç YOLO - Detecci√≥n de objetos]
    B --> C[‚úã MediaPipe - An√°lisis de landmarks / gestos]
    B --> D[üåä MiDaS - Estimaci√≥n de profundidad]
    B --> E[üé≠ SAM - Segmentaci√≥n precisa]
    D --> F[üìä Evaluaci√≥n de cercan√≠a y √°rea ocupada]
    E --> F
    F --> G[üìà Salida: An√°lisis visual y m√©tricas]
```

| Etapa                 | Descripci√≥n                                                                             |
| --------------------- | --------------------------------------------------------------------------------------- |
| **YOLO**              | Detecta clases relevantes (carros, peatones, bicicletas) y genera bounding boxes.       |
| **MediaPipe**         | Analiza puntos clave (landmarks) en manos o cuerpo para entender interacciones humanas. |
| **MiDaS**             | Calcula un mapa de profundidad monocular, usado para estimar distancias relativas.      |
| **SAM**               | Genera m√°scaras precisas por objeto para segmentaci√≥n y c√°lculo de √°rea.                |
| **Postprocesamiento** | Integra los resultados, calcula m√©tricas y visualiza el pipeline completo.              |

---

## Par√°metros clave

| Modelo        | Par√°metro          | Valor / Descripci√≥n                          |
| ------------- | ------------------ | -------------------------------------------- |
| **YOLO**      | `modelo`           | yolov8n.pt (versi√≥n ligera para tiempo real) |
|               | `conf_threshold`   | 0.45                                         |
|               | `nms_threshold`    | 0.5                                          |
|               | `imgsz`            | 640x640                                      |
| **MediaPipe** | `task`             | Hands / Pose                                 |
|               | `FPS`              | ~20‚Äì25                                       |
|               | `landmarks usados` | mu√±eca, √≠ndice, pulgar, centro de palma      |
| **MiDaS**     | `versi√≥n`          | DPT-Hybrid                                   |
|               | `normalizaci√≥n`    | min‚Äìmax a [0,1]                              |
| **SAM**       | `prompt`           | caja (bbox de YOLO)                          |
|               | `checkpoint`       | vit_b (base)                                 |

---

## M√©tricas

| M√©trica                | Descripci√≥n                                     | Valor estimado  |
| ---------------------- | ----------------------------------------------- | --------------- |
| **Latencia total**     | Tiempo promedio por frame                       | ~140 ms         |
| **IoU (m√°scaras)**     | Coincidencia entre m√°scaras SAM y √°reas YOLO    | 0.82            |
| **% cercan√≠a (MiDaS)** | Objetos clasificados como cerca / medio / lejos | 38% / 41% / 21% |
| **FPS**                | Velocidad de procesamiento total                | ~7 FPS          |

## ‚ö†Ô∏è Limitaciones

Ruido en el mapa de profundidad para objetos oscuros o reflejantes.

Oclusiones entre peatones o veh√≠culos reducen la precisi√≥n de SAM.

Sensibilidad a cambios de iluminaci√≥n o movimiento r√°pido.

MediaPipe puede fallar en detecci√≥n de landmarks si la resoluci√≥n es baja.

## üöÄ Futuro del Proyecto

üîÅ SAM 2: Segmentaci√≥n temporal para video con coherencia entre frames.

‚ö° Cuantizaci√≥n: Reducir tama√±o y latencia de los modelos.

üéØ Seguimiento multi-objeto (DeepSORT o ByteTrack).

‚òÅÔ∏è Despliegue en edge devices (Jetson Nano, Coral TPU).

üìâ An√°lisis estad√≠stico de flujos de tr√°fico y comportamiento de peatones.
